<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>Easymap</title>
<style>
* { font-family: sans; line-height:1.1em; }
code , pre,
code > * , pre > *
 {
   color: green;
   margin: 3px;
   background-color: #DDD;
   font-family:mono !important; 
}
</style>

<head>
<!--script src="./map_v1.js"></script -->
<!--link rel="stylesheet" type="text/css" href="./map_v1.css" /-->
</head>

<body onLoad='onPageLoaded()'>
<div id='zoomDiv'></div>
<div style="position:fixed; right:0.3%; bottom:0; width:auto;">
<b style="font-size:1.5rem" orange><a onclick="onZoomOut()">[-A]</a></b>
<b style="font-size:1.5rem"       >                                 </b>
<b style="font-size:2.0rem" orange><a onclick="onZoomIn ()">[A+]</a></b>
</div>
<!-- {{{ START }}} -->

  <b>ABOUT:</b>
  <ul zoom>
  <li>Keep it simple and stupid remote backup script:</li>
  <li>This system just care about easifying the backup part
    mirrowing content to remote machines with the help of ssh+rsync</li>
  <li>It doesn't provide any tool to recover. It's up to users/admin to copy back from mirrow copies to restore data</li>
  <li>rsync <code>--link-dest "referenceBackup"</code> is used to create incremental backups based on last-day backup.<br/>
      <code>--link-dest</code> flag indicates that in case in which a file match in "referenceBackup" and new backup,
      only a hard-link (not the full file) will be created. This will create two paths to the same file wasting no extra-space.</li>
  <li>backups "accumulate" on remote destination until they will fill-up the remote hardisk.<br/>
      This script does NOT care about it. It's up to admin to create a remote script to remove old backups
      following the UNIX philosophy of "DO ONE THING AND DO IT RIGHT!".<br/>
      The good news: It's very easy to create such a remote script since backups are tagged with YYYYmmdd suffix. 
      Example file to remote backups older than 30 days:
<pre>
DATE=`date --date='30 day' +%Y%m%d`
rm -rf /var/backups/repository01/*$DATE 
# TIP: Notice that rm -rf ...' will just decrease the reference count to existing files
#      if newer backups still point to a given file that increased the ref.count trough
#      the --link-dest option
</pre>

  </li>
  </ul>

  <b>PREREQUISITES:</b>
  <ul>
  <li>Any system compatible with bash+rsync+ssh must work (tested on Linux)</li>
  </ul>

  <b>USSAGE: CONFIGURATION:</b>
  <ul>
  <li>Step 1: (optional but recomended) Mentally divide backups into projects with different dependencies/life-cycles</li>
  <li>Step 2: Create a central backup directory for each user with different permissions, for
     example <code>/home/myUser/easyup/</code>. Inside it create a layout structure similar to:
<pre>
etc/easyup.conf   ← Central configuration file (can be created dynamically)
var/build_config  ← (Optional). Creates etc/easyup.conf before starting the backup
BACKUP.sh         ← Shell script organizing backups
</pre>
</li>
  <li>Step 3. Alternative 1: (discouraged for all but simplest cases) Create an handwritten <code>etc/easyup.conf</code> with all the info
    about backups. The config flow will be:
<pre>
 start → etc/easyup.conf → (input to) BACKUP.sh
</pre>
  
  The file will look similar to:
<pre>
# lines starting with '#' will be ignored.
# Note: SSH port is obligatory, even if using the default 22
/home/user2/project2:myUser1:myRemoteServer1:2221:/var/lib/backups/repositories
/home/user2/project1:myUser2:myRemoteServer2:2222:/var/lib/backups/repositories
/home/user2/project2:myUser2:myRemoteServer2:2222:/var/lib/backups/repositories
^^^^^^^^^^^^^^^^^^^^ ^^^^^^^ ^^^^^^^^^^^^^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  
   DIR or FILE        ssh        ssh         ssh   destination (parent) directory
    to backup         user      server       port  in remote ssh server for mirror
                                                   copies
</pre>
  </li>
  <li>Step 3. Alternative 2: (prefered for all but the simplest cases) <br/>
  Create an executable script <code>var/build_config</code> in charge of programatically write the <code>etc/easyup.conf</code><br/>
    The script is executed by BACKUP.sh to create <code>etc/easyup.conf</code> programatically before reading it as final configuration. <code>var/build_config</code> can use the ENV.VAR 'CONFIG_FILE' to known where the config output is expected to be found.<br/>
   NOTE: Use <code>$CONFIG_FILE</code> instead of <code>etc/easyup.conf</code> to protect from future changes to protect from future changes
   <br/>
   The config flow will be:
<pre>
 start → exec var/build_config → (output to) → etc/easyup.conf → (input to) → BACKUP.sh
</pre>
<br/>
  An example <code>var/build_config</code> (bash) script can look similar to:
<pre>
remoteDest<b>1</b>="myRemoteUser:myRemoteBackupServer<b>1</b>.com:2112:/var/lib/backups"
remoteDest<b>2</b>="myRemoteUser:myRemoteBackupServer<b>2</b>.com:22:/var/lib/backups"

PROJECT<b>1</b>_SRC="/home/myUser/project<b>1</b>"
PROJECT<b>2</b>_SRC="/home/myUser/project<b>2</b>"

<b>cat &lt;&lt; EOF &gt;${CONFIG_FILE}</b>
# generated by var/build_config
${PROJECT01_SRC}:${remoteDest<b>1</b>}
${PROJECT02_SRC}:${remoteDest<b>1</b>}
${PROJECT01_SRC}:${remoteDest<b>2</b>}
${PROJECT02_SRC}:${remoteDest<b>2</b>}
<b orange>EOF</b>
</pre>
  </li>
  <li>Step 4 (Optional) *For each DIR or FILE source*, BACKUP.sh will check if there is a corresponding
<code>$DIR/easyup.conf or $FILE.easyup.conf</code> and include it as part of the bash backup script.
This script can be used to override default RSYNC_EXTRA_DIR_OPTS, including files or directories,...
<pre>
# Example ${PROJECT01_SRC}/easyup.conf file. Exclude files from backup/rsync:
RSYNC_EXTRA_DIR_OPTS=""
RSYNC_EXTRA_DIR_OPTS="${RSYNC_EXTRA_DIR_OPTS} --exclude 'CEMENTERY' "
RSYNC_EXTRA_DIR_OPTS="${RSYNC_EXTRA_DIR_OPTS} --exclude='*logs'     "
RSYNC_EXTRA_DIR_OPTS="${RSYNC_EXTRA_DIR_OPTS} --exclude='*class'    "
RSYNC_EXTRA_DIR_OPTS="${RSYNC_EXTRA_DIR_OPTS} --exclude='target'    "
</pre>
  </li>
  <li>Step 5 (Optional) *For each DIR or FILE source*, BACKUP.sh will check if there is a corresponding
<code>$DIR/easyup.sh or $FILE.easyup.sh</code> and execute it as a separate backup script.
This script can be used to dump a database, serialize running state, ...
<pre>
# Example ${PROJECT01_SRC}/easyup.sh file to dump a Postgresql DDBB

cd "MyProjectHome"
source CONFIG_ENVIRONMENT
# dump  Postgresql Container DDBB to ddbb.backup.sql
# that in the next step will then be "rsynced" to remote ssh host
sudo docker exec ${DOCKER_POSTGRESQL_CONTAINERID} \
    pg_dump --username=$DB_USER $DDBB_NAME 2&gt;&amp;1 | cat - &gt; ddbb.backup.sql
</pre>
  </li>
  </ul>
  <b>USSAGE: EXECUTION:</b>
  <ul>
  <li>Once everything is configured just exec ./BACKUP.sh to trigger copies 
    (or add execution to cron system)</li>
  <li>Check error logs for backup failures</li>
  </ul>
</body>
</html>
